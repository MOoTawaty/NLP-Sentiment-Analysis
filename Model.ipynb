{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "862ca7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2dc9f",
   "metadata": {},
   "source": [
    "# Cleaning &  Preparing the data to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "b34aba3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': True, 'is': True, 'an': True, 'interest': True, 'boy': True}"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def format_sentence(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('\\s+', ' ', sent) #exstra space\n",
    "    sent = ' '.join([stemmer.stem(word) for word in re.split('\\s+', sent)]) #Stemming\n",
    "    sent = re.sub(\"[^0-9A-Za-z ]\", \"\", sent) #Punctuations \n",
    "    return {word: (word in word_tokenize(sent)) for word in word_tokenize(sent)}\n",
    "\n",
    "format_sentence('this’’s is an interesting boy   @#!$%^&')  #testing sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "a64cc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', encoding= 'unicode_escape').values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294a992",
   "metadata": {},
   "source": [
    "## Reading the Financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "e2662c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = []\n",
    "neg_data = []\n",
    "neu_data = []\n",
    "\n",
    "for rew in range(len(data)):\n",
    "    record = data[rew]\n",
    "    line = str(record[0])   \n",
    "    category = str(record[1])\n",
    "    if(category == 'positive'):\n",
    "        pos_data.append([format_sentence(line), 'pos'])\n",
    "    elif(category == 'negative'):\n",
    "        neg_data.append([format_sentence(line), 'neg'])\n",
    "    elif(category == 'neutral'):\n",
    "        neu_data.append([format_sentence(line), 'neut'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "8d315764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852 860 3130\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_data), len(neg_data), len(neu_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406ef44",
   "metadata": {},
   "source": [
    "## Reading the question data to enhance neutrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "9ac20f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('questions.csv', ).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "c0e13798",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_questions = []\n",
    "\n",
    "for rew in range(1500):\n",
    "    record = data[rew]\n",
    "    line = str(record[3])   \n",
    "    neu_questions.append([format_sentence(line), 'neut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885d040",
   "metadata": {},
   "source": [
    "### Reading extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "0c8f9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "posit_data = []\n",
    "with open('extra.pos.txt', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        posit_data.append([format_sentence(line), 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "cdc045b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "negat_data = []\n",
    "with open('extra.neg.txt', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        negat_data.append([format_sentence(line), 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "a080d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data.extend(posit_data)\n",
    "neg_data.extend(negat_data)\n",
    "neu_data.extend(neu_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "dd3c22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7183 6191 4630\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_data), len(neg_data), len(neu_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "a7142f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pos_data[:6800] + neg_data[:4900] + neu_data[1000:] \n",
    "testing_data  = pos_data[6800:] + neg_data[4000:] + neu_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "b6a222d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15330 3574\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data), len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "3d0d43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "model = NaiveBayesClassifier.train(training_data)\n",
    "#model.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "b4144972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n",
      "neut\n",
      "neut\n",
      "neut\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(format_sentence('this is a nice boy!')))\n",
    "print(model.classify(format_sentence('this is a bad boy!')))\n",
    "print(model.classify(format_sentence('what is ur name?')))\n",
    "print(model.classify(format_sentence('Viking Line has canceled some services.')))\n",
    "print(model.classify(format_sentence('my name is Mohamed Khalid.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "2818af41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640179071068831"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "accuracy(model, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1f235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c57bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
